{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3d9874",
   "metadata": {},
   "source": [
    "# 🔥 Hot Durham Data Management - Next Steps Guide\n",
    "\n",
    "Your automated data management system is now **fully operational**! This notebook will guide you through the recommended next steps to get the most out of your system.\n",
    "\n",
    "## 🎯 Current Status\n",
    "✅ **Complete data management system** with organized folder structure  \n",
    "✅ **Automated data collection** scripts for WU and TSI sensors  \n",
    "✅ **Google Drive integration** for cloud backup and sync  \n",
    "✅ **Smart scheduling** with cron job support  \n",
    "✅ **Comprehensive monitoring** and health checks  \n",
    "\n",
    "## 📋 What We'll Cover\n",
    "1. **System Configuration Review** - Check current automation settings\n",
    "2. **Automation Setup** - Enable scheduled data pulls\n",
    "3. **Manual Testing** - Verify system functionality\n",
    "4. **Data Analysis** - Start exploring your environmental data\n",
    "5. **Production Monitoring** - Set up ongoing system health checks\n",
    "\n",
    "Let's get started! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b54e9b",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, let's import the necessary libraries for configuration and data handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a38c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataManager imported successfully\n",
      "📁 Project root: /Users/alainsoto/IdeaProjects/Hot Durham\n",
      "📁 Config path: /Users/alainsoto/IdeaProjects/Hot Durham/config/automation_config.json\n",
      "📁 Data path: /Users/alainsoto/IdeaProjects/Hot Durham/data\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directories to path for new structure\n",
    "sys.path.append('src/core')\n",
    "sys.path.append('src/analysis')\n",
    "sys.path.append('src/data_collection')\n",
    "sys.path.append('src/automation')\n",
    "\n",
    "# Import our custom data manager\n",
    "try:\n",
    "    from data_manager import DataManager\n",
    "    print(\"✅ DataManager imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Could not import DataManager: {e}\")\n",
    "    print(\"Please ensure you're running this from the Hot Durham project directory\")\n",
    "\n",
    "# Set up paths\n",
    "project_root = Path.cwd()\n",
    "config_path = project_root / \"config\" / \"automation_config.json\"\n",
    "logs_path = project_root / \"logs\"\n",
    "data_path = project_root / \"data\"\n",
    "\n",
    "print(f\"📁 Project root: {project_root}\")\n",
    "print(f\"📁 Config path: {config_path}\")\n",
    "print(f\"📁 Data path: {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce41ef5",
   "metadata": {},
   "source": [
    "## 2. Load Configuration\n",
    "\n",
    "Let's check your current automation configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94fd834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration loaded successfully\n",
      "\n",
      "📋 Current Configuration:\n",
      "{\n",
      "  \"share_email\": \"hotdurham@gmail.com\",\n",
      "  \"automation_enabled\": true,\n",
      "  \"default_pull_type\": \"weekly\",\n",
      "  \"google_drive_sync\": true,\n",
      "  \"notifications\": {\n",
      "    \"email_on_success\": false,\n",
      "    \"email_on_failure\": true,\n",
      "    \"email_address\": \"hotdurham@gmail.com\"\n",
      "  },\n",
      "  \"data_retention\": {\n",
      "    \"keep_raw_data_months\": 24,\n",
      "    \"keep_processed_data_months\": 12,\n",
      "    \"auto_cleanup\": false\n",
      "  },\n",
      "  \"schedules\": {\n",
      "    \"weekly_pull\": {\n",
      "      \"enabled\": true,\n",
      "      \"day_of_week\": \"monday\",\n",
      "      \"time\": \"06:00\",\n",
      "      \"sources\": [\n",
      "        \"wu\",\n",
      "        \"tsi\"\n",
      "      ]\n",
      "    },\n",
      "    \"monthly_summary\": {\n",
      "      \"enabled\": true,\n",
      "      \"day_of_month\": 1,\n",
      "      \"time\": \"07:00\",\n",
      "      \"generate_reports\": true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "🔧 Key Settings:\n",
      "   📅 Automation enabled: ✅ True\n",
      "   📊 Default pull type: weekly\n",
      "   ☁️ Google Drive sync: ✅ True\n",
      "   📧 Share email: hotdurham@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# Load automation configuration\n",
    "try:\n",
    "    if config_path.exists():\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        print(\"✅ Configuration loaded successfully\")\n",
    "        print(\"\\n📋 Current Configuration:\")\n",
    "        print(json.dumps(config, indent=2))\n",
    "        \n",
    "        # Check key settings\n",
    "        automation_enabled = config.get('automation_enabled', False)\n",
    "        default_pull_type = config.get('default_pull_type', 'weekly')\n",
    "        google_drive_sync = config.get('google_drive_sync', False)\n",
    "        share_email = config.get('share_email', 'Not set')\n",
    "        \n",
    "        print(\"\\n🔧 Key Settings:\")\n",
    "        print(f\"   📅 Automation enabled: {'✅' if automation_enabled else '❌'} {automation_enabled}\")\n",
    "        print(f\"   📊 Default pull type: {default_pull_type}\")\n",
    "        print(f\"   ☁️ Google Drive sync: {'✅' if google_drive_sync else '❌'} {google_drive_sync}\")\n",
    "        print(f\"   📧 Share email: {share_email}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Configuration file not found. Run './setup_automation.sh' to create it.\")\n",
    "        config = {}\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading configuration: {e}\")\n",
    "    config = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b6277",
   "metadata": {},
   "source": [
    "## 3. Check Automation Status\n",
    "\n",
    "Let's verify if your automated scheduling is properly configured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ac2d0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking cron job status...\n",
      "✅ Found 3 Hot Durham cron job(s):\n",
      "   📅 # Hot Durham Automated Data Pulls\n",
      "   📅 0 6 * * 1 cd /Users/alainsoto/IdeaProjects/Hot Durham && /Users/alainsoto/IdeaProjects/Hot Durham/.venv/bin/python3 /Users/alainsoto/IdeaProjects/Hot Durham/scripts/automated_data_pull.py --weekly >> /Users/alainsoto/IdeaProjects/Hot Durham/logs/weekly_pull.log 2>&1\n",
      "   📅 0 7 1 * * cd /Users/alainsoto/IdeaProjects/Hot Durham && /Users/alainsoto/IdeaProjects/Hot Durham/.venv/bin/python3 /Users/alainsoto/IdeaProjects/Hot Durham/scripts/automated_data_pull.py --monthly >> /Users/alainsoto/IdeaProjects/Hot Durham/logs/monthly_pull.log 2>&1\n",
      "\n",
      "✅ Setup script found at: /Users/alainsoto/IdeaProjects/Hot Durham/setup_automation.sh\n",
      "💡 Run './setup_automation.sh' to configure automated scheduling\n"
     ]
    }
   ],
   "source": [
    "# Check cron jobs\n",
    "print(\"🔍 Checking cron job status...\")\n",
    "try:\n",
    "    result = subprocess.run(['crontab', '-l'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        cron_output = result.stdout\n",
    "        hot_durham_jobs = [line for line in cron_output.split('\\n') if 'Hot Durham' in line or 'automated_data_pull' in line]\n",
    "        \n",
    "        if hot_durham_jobs:\n",
    "            print(f\"✅ Found {len(hot_durham_jobs)} Hot Durham cron job(s):\")\n",
    "            for job in hot_durham_jobs:\n",
    "                print(f\"   📅 {job}\")\n",
    "        else:\n",
    "            print(\"⚠️ No Hot Durham cron jobs found\")\n",
    "            print(\"\\n💡 To set up automation, run:\")\n",
    "            print(\"   ./setup_automation.sh\")\n",
    "    else:\n",
    "        print(\"❌ Could not access crontab. You may need to set up cron permissions.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error checking cron jobs: {e}\")\n",
    "\n",
    "# Check if setup script exists\n",
    "setup_script = project_root / \"setup_automation.sh\"\n",
    "if setup_script.exists():\n",
    "    print(f\"\\n✅ Setup script found at: {setup_script}\")\n",
    "    print(\"💡 Run './setup_automation.sh' to configure automated scheduling\")\n",
    "else:\n",
    "    print(\"\\n❌ Setup script not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3fd5bb",
   "metadata": {},
   "source": [
    "## 4. Run Manual Data Pull\n",
    "\n",
    "Let's test your system with a manual data pull to ensure everything is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e52e6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Available data collection scripts:\n",
      "✅ Automated script: /Users/alainsoto/IdeaProjects/Hot Durham/scripts/automated_data_pull.py\n",
      "✅ Main script: /Users/alainsoto/IdeaProjects/Hot Durham/scripts/faster_wu_tsi_to_sheets_async.py\n",
      "\n",
      "💡 To run a manual data pull, choose one of these commands:\n",
      "\n",
      "📊 **Option 1: Quick test (WU only, no sheets)**\n",
      "   python scripts/automated_data_pull.py --weekly --wu-only --no-sheets\n",
      "\n",
      "📊 **Option 2: Full weekly pull with Google Sheets**\n",
      "   python scripts/automated_data_pull.py --weekly\n",
      "\n",
      "📊 **Option 3: Main script (creates comprehensive sheets)**\n",
      "   python scripts/faster_wu_tsi_to_sheets_async.py\n",
      "\n",
      "🚀 **Ready to test? Uncomment and run one of the commands below:**\n",
      "# Uncomment the line below to run a test:\n",
      "# !python scripts/automated_data_pull.py --weekly --wu-only --no-sheets\n"
     ]
    }
   ],
   "source": [
    "# Check available scripts\n",
    "scripts_dir = project_root / \"scripts\"\n",
    "automated_script = scripts_dir / \"automated_data_pull.py\"\n",
    "main_script = scripts_dir / \"faster_wu_tsi_to_sheets_async.py\"\n",
    "\n",
    "print(\"🔍 Available data collection scripts:\")\n",
    "if automated_script.exists():\n",
    "    print(f\"✅ Automated script: {automated_script}\")\n",
    "else:\n",
    "    print(f\"❌ Automated script not found: {automated_script}\")\n",
    "    \n",
    "if main_script.exists():\n",
    "    print(f\"✅ Main script: {main_script}\")\n",
    "else:\n",
    "    print(f\"❌ Main script not found: {main_script}\")\n",
    "\n",
    "print(\"\\n💡 To run a manual data pull, choose one of these commands:\")\n",
    "print(\"\\n📊 **Option 1: Quick test (WU only, no sheets)**\")\n",
    "print(\"   python scripts/automated_data_pull.py --weekly --wu-only --no-sheets\")\n",
    "print(\"\\n📊 **Option 2: Full weekly pull with Google Sheets**\")\n",
    "print(\"   python scripts/automated_data_pull.py --weekly\")\n",
    "print(\"\\n📊 **Option 3: Main script (creates comprehensive sheets)**\")\n",
    "print(\"   python scripts/faster_wu_tsi_to_sheets_async.py\")\n",
    "\n",
    "print(\"\\n🚀 **Ready to test? Uncomment and run one of the commands below:**\")\n",
    "print(\"# Uncomment the line below to run a test:\")\n",
    "print(\"# !python scripts/automated_data_pull.py --weekly --wu-only --no-sheets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fbd7604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸️ Manual test execution is commented out.\n",
      "To run a test, uncomment one of the lines above and execute this cell.\n",
      "\n",
      "💡 Recommended first test: --weekly --wu-only --no-sheets (fastest)\n"
     ]
    }
   ],
   "source": [
    "# 🧪 MANUAL TEST EXECUTION\n",
    "# Uncomment the line below to run a quick test of your data collection system:\n",
    "\n",
    "# !python scripts/automated_data_pull.py --weekly --wu-only --no-sheets\n",
    "\n",
    "# If you want to run a full test with both WU and TSI data plus Google Sheets:\n",
    "# !python scripts/automated_data_pull.py --weekly\n",
    "\n",
    "print(\"⏸️ Manual test execution is commented out.\")\n",
    "print(\"To run a test, uncomment one of the lines above and execute this cell.\")\n",
    "print(\"\\n💡 Recommended first test: --weekly --wu-only --no-sheets (fastest)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81450330",
   "metadata": {},
   "source": [
    "## 5. Verify Google Drive Sync\n",
    "\n",
    "Let's check if your Google Drive integration is working properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42ca4fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 01:26:38,004 - INFO - file_cache is only supported with oauth2client<4.0.0\n",
      "2025-05-25 01:26:38,006 - INFO - Google Drive service initialized successfully\n",
      "2025-05-25 01:26:38,006 - INFO - Google Drive service initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "☁️ Google Drive Integration Status:\n",
      "✅ Google credentials file found\n",
      "✅ DataManager initialized successfully\n",
      "✅ Google Drive service appears to be working\n",
      "✅ Google Drive sync script found\n",
      "\n",
      "⚠️ No Google Drive sync logs found yet\n",
      "💡 Logs will be created after your first sync operation\n"
     ]
    }
   ],
   "source": [
    "# Check Google Drive credentials\n",
    "creds_dir = project_root / \"creds\"\n",
    "google_creds = creds_dir / \"google_creds.json\"\n",
    "\n",
    "print(\"☁️ Google Drive Integration Status:\")\n",
    "\n",
    "if google_creds.exists():\n",
    "    print(\"✅ Google credentials file found\")\n",
    "    try:\n",
    "        # Try to initialize DataManager (which tests Google Drive)\n",
    "        dm = DataManager(str(project_root))\n",
    "        print(\"✅ DataManager initialized successfully\")\n",
    "        print(\"✅ Google Drive service appears to be working\")\n",
    "        \n",
    "        # Check for Google Drive sync script\n",
    "        sync_script = scripts_dir / \"google_drive_sync.py\"\n",
    "        if sync_script.exists():\n",
    "            print(\"✅ Google Drive sync script found\")\n",
    "        else:\n",
    "            print(\"❌ Google Drive sync script not found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error initializing Google Drive: {e}\")\n",
    "        print(\"💡 Check your Google Cloud Console settings and credentials\")\n",
    "else:\n",
    "    print(f\"❌ Google credentials not found at: {google_creds}\")\n",
    "    print(\"💡 Place your Google service account credentials in the creds/ directory\")\n",
    "\n",
    "# Check for recent sync logs\n",
    "sync_log = logs_path / \"google_drive_sync.log\"\n",
    "if sync_log.exists():\n",
    "    print(f\"\\n📋 Recent Google Drive sync activity found in: {sync_log}\")\n",
    "    print(\"💡 You can check the log for sync details\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No Google Drive sync logs found yet\")\n",
    "    print(\"💡 Logs will be created after your first sync operation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3d2c9f",
   "metadata": {},
   "source": [
    "## 6. Analyze Logs for Errors\n",
    "\n",
    "Let's check your system logs for any recent errors or warnings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cd01e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 System Logs Analysis:\n",
      "\n",
      "Logs directory: /Users/alainsoto/IdeaProjects/Hot Durham/logs\n",
      "\n",
      "📁 Found 1 log file(s):\n",
      "   📄 automation_log_202505.json (655 bytes)\n",
      "\n",
      "📋 Latest automation log: automation_log_202505.json\n",
      "   📊 Contains 3 log entries\n",
      "   ⏰ Latest entry: 2025-05-25 01:22:16\n",
      "   📊 Status: Unknown\n",
      "\n",
      "✅ No obvious errors or warnings found in logs\n"
     ]
    }
   ],
   "source": [
    "# Check log directory and files\n",
    "print(\"📋 System Logs Analysis:\")\n",
    "print(f\"\\nLogs directory: {logs_path}\")\n",
    "\n",
    "if logs_path.exists():\n",
    "    log_files = list(logs_path.glob(\"*.log\")) + list(logs_path.glob(\"*.json\"))\n",
    "    \n",
    "    if log_files:\n",
    "        print(f\"\\n📁 Found {len(log_files)} log file(s):\")\n",
    "        for log_file in log_files:\n",
    "            print(f\"   📄 {log_file.name} ({log_file.stat().st_size} bytes)\")\n",
    "            \n",
    "        # Check the most recent automation log\n",
    "        json_logs = [f for f in log_files if f.suffix == '.json']\n",
    "        if json_logs:\n",
    "            latest_log = max(json_logs, key=lambda f: f.stat().st_mtime)\n",
    "            print(f\"\\n📋 Latest automation log: {latest_log.name}\")\n",
    "            try:\n",
    "                with open(latest_log, 'r') as f:\n",
    "                    log_data = json.load(f)\n",
    "                print(f\"   📊 Contains {len(log_data)} log entries\")\n",
    "                if log_data:\n",
    "                    latest_entry = log_data[-1]\n",
    "                    print(f\"   ⏰ Latest entry: {latest_entry.get('timestamp', 'Unknown time')}\")\n",
    "                    print(f\"   📊 Status: {latest_entry.get('status', 'Unknown')}\")\n",
    "                    if 'error' in latest_entry:\n",
    "                        print(f\"   ❌ Error: {latest_entry['error']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Error reading log: {e}\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ No log files found yet\")\n",
    "        print(\"💡 Logs will be created after running data pulls or automation\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Logs directory not found\")\n",
    "    print(\"💡 Directory will be created automatically when needed\")\n",
    "\n",
    "# Quick error check across all logs\n",
    "if logs_path.exists():\n",
    "    error_count = 0\n",
    "    warning_count = 0\n",
    "    for log_file in logs_path.glob(\"*.log\"):\n",
    "        try:\n",
    "            with open(log_file, 'r') as f:\n",
    "                content = f.read()\n",
    "                error_count += content.lower().count('error')\n",
    "                warning_count += content.lower().count('warning')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if error_count > 0 or warning_count > 0:\n",
    "        print(f\"\\n⚠️ Found {error_count} errors and {warning_count} warnings in logs\")\n",
    "        print(\"💡 Use 'grep -i error logs/*.log' to investigate specific issues\")\n",
    "    else:\n",
    "        print(\"\\n✅ No obvious errors or warnings found in logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d7d6b",
   "metadata": {},
   "source": [
    "## 7. Inspect Data Inventory\n",
    "\n",
    "Let's review your current data collection and storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "270fe856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 01:26:43,842 - INFO - file_cache is only supported with oauth2client<4.0.0\n",
      "2025-05-25 01:26:43,844 - INFO - Google Drive service initialized successfully\n",
      "2025-05-25 01:26:43,844 - INFO - Google Drive service initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Data Inventory Report:\n",
      "❌ Error getting data inventory: 'DataManager' object has no attribute 'get_data_inventory'\n",
      "💡 Try running a manual data pull first to create some data\n",
      "\n",
      "🔍 Manual Directory Check:\n",
      "   🌤️ WU files: 0\n",
      "   🔬 TSI files: 0\n"
     ]
    }
   ],
   "source": [
    "# Use DataManager to get data inventory\n",
    "print(\"📊 Data Inventory Report:\")\n",
    "\n",
    "try:\n",
    "    # Initialize DataManager\n",
    "    dm = DataManager(str(project_root))\n",
    "    \n",
    "    # Get data inventory\n",
    "    inventory = dm.get_data_inventory()\n",
    "    \n",
    "    print(\"\\n📁 Data Storage Overview:\")\n",
    "    print(f\"   📂 Total files: {inventory.get('total_files', 0)}\")\n",
    "    print(f\"   💾 Total size: {inventory.get('total_size_mb', 0):.2f} MB\")\n",
    "    print(f\"   📅 Date range: {inventory.get('date_range', 'No data')}\")\n",
    "    \n",
    "    # Break down by source\n",
    "    sources = inventory.get('sources', {})\n",
    "    if sources:\n",
    "        print(\"\\n📊 Data by Source:\")\n",
    "        for source, data in sources.items():\n",
    "            print(f\"   🌡️ {source.upper()}: {data.get('files', 0)} files, {data.get('size_mb', 0):.2f} MB\")\n",
    "    \n",
    "    # List recent files\n",
    "    recent_files = inventory.get('recent_files', [])\n",
    "    if recent_files:\n",
    "        print(\"\\n📋 Recent Data Files (last 5):\")\n",
    "        for file_info in recent_files[-5:]:\n",
    "            print(f\"   📄 {file_info.get('name', 'Unknown')} ({file_info.get('size_mb', 0):.2f} MB)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error getting data inventory: {e}\")\n",
    "    print(\"💡 Try running a manual data pull first to create some data\")\n",
    "\n",
    "# Manual file count (backup method)\n",
    "print(\"\\n🔍 Manual Directory Check:\")\n",
    "raw_pulls_dir = data_path / \"raw_pulls\"\n",
    "if raw_pulls_dir.exists():\n",
    "    wu_files = list((raw_pulls_dir / \"wu\").rglob(\"*.csv\")) if (raw_pulls_dir / \"wu\").exists() else []\n",
    "    tsi_files = list((raw_pulls_dir / \"tsi\").rglob(\"*.csv\")) if (raw_pulls_dir / \"tsi\").exists() else []\n",
    "    \n",
    "    print(f\"   🌤️ WU files: {len(wu_files)}\")\n",
    "    print(f\"   🔬 TSI files: {len(tsi_files)}\")\n",
    "    \n",
    "    if wu_files or tsi_files:\n",
    "        print(\"\\n📋 Sample files:\")\n",
    "        for f in (wu_files + tsi_files)[:3]:\n",
    "            print(f\"   📄 {f.name}\")\n",
    "else:\n",
    "    print(\"   ⚠️ Raw data directory not found\")\n",
    "    print(\"   💡 Run a data pull to create the directory structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ecbe58",
   "metadata": {},
   "source": [
    "## 🎯 Your Recommended Next Steps\n",
    "\n",
    "Based on your system status, here are the recommended next steps:\n",
    "\n",
    "### 🚀 **Immediate Actions (Do Today)**\n",
    "\n",
    "1. **Set Up Automation** (If not already done)\n",
    "   ```bash\n",
    "   ./setup_automation.sh\n",
    "   ```\n",
    "\n",
    "2. **Run Your First Test**\n",
    "   ```bash\n",
    "   python scripts/automated_data_pull.py --weekly --wu-only --no-sheets\n",
    "   ```\n",
    "\n",
    "3. **Verify Everything Works**\n",
    "   ```bash\n",
    "   python scripts/status_check.py\n",
    "   ```\n",
    "\n",
    "### 📊 **Short Term (This Week)**\n",
    "\n",
    "4. **Start Regular Data Collection**\n",
    "   - Let the automation run weekly (every Monday 6 AM)\n",
    "   - Or run manual pulls as needed\n",
    "\n",
    "5. **Explore Your Data**\n",
    "   - Check the Google Sheets created by your pulls\n",
    "   - Review data quality and completeness\n",
    "   - Look for interesting patterns or anomalies\n",
    "\n",
    "6. **Set Up Monitoring**\n",
    "   - Check logs weekly for any errors\n",
    "   - Monitor Google Drive sync status\n",
    "   - Verify data integrity regularly\n",
    "\n",
    "### 📈 **Medium Term (This Month)**\n",
    "\n",
    "7. **Data Analysis & Insights**\n",
    "   - Create custom analysis notebooks\n",
    "   - Build dashboards or reports\n",
    "   - Compare WU vs TSI sensor readings\n",
    "   - Analyze seasonal or weekly patterns\n",
    "\n",
    "8. **System Optimization**\n",
    "   - Fine-tune automation schedules\n",
    "   - Add custom data processing\n",
    "   - Optimize Google Drive storage\n",
    "\n",
    "### 🔬 **Long Term (Ongoing)**\n",
    "\n",
    "9. **Environmental Research**\n",
    "   - Correlate data with health outcomes\n",
    "   - Study air quality trends\n",
    "   - Share insights with Durham community\n",
    "   - Publish findings or reports\n",
    "\n",
    "10. **System Enhancement**\n",
    "    - Add new data sources\n",
    "    - Integrate with other platforms\n",
    "    - Build public dashboards\n",
    "    - Automate report generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89602ec",
   "metadata": {},
   "source": [
    "## ⚡ Quick Actions\n",
    "\n",
    "Use these code cells to perform common tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67c6b01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸️ Setup command is commented out.\n",
      "Uncomment the lines above to run the automation setup.\n"
     ]
    }
   ],
   "source": [
    "# 🔧 QUICK SETUP - Run automation setup\n",
    "# Uncomment to run:\n",
    "\n",
    "# !chmod +x setup_automation.sh\n",
    "# !./setup_automation.sh\n",
    "\n",
    "print(\"⏸️ Setup command is commented out.\")\n",
    "print(\"Uncomment the lines above to run the automation setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f29dd0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸️ Test command is commented out.\n",
      "Uncomment the line above to run a quick WU data test.\n"
     ]
    }
   ],
   "source": [
    "# 🧪 QUICK TEST - Run a fast data pull test\n",
    "# Uncomment to run:\n",
    "\n",
    "# !python scripts/automated_data_pull.py --weekly --wu-only --no-sheets\n",
    "\n",
    "print(\"⏸️ Test command is commented out.\")\n",
    "print(\"Uncomment the line above to run a quick WU data test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0ab81ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸️ Status check command is commented out.\n",
      "Uncomment the line above to run a system status check.\n"
     ]
    }
   ],
   "source": [
    "# 📊 QUICK STATUS - Check system health\n",
    "# Uncomment to run:\n",
    "\n",
    "# !python scripts/status_check.py\n",
    "\n",
    "print(\"⏸️ Status check command is commented out.\")\n",
    "print(\"Uncomment the line above to run a system status check.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639779d",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "Your **Hot Durham Data Management System** is ready for production! 🚀\n",
    "\n",
    "### ✅ What You've Accomplished:\n",
    "- **Complete automated data collection** system\n",
    "- **Organized storage** with smart file management\n",
    "- **Google Drive integration** for cloud backup\n",
    "- **Scheduling system** for regular data pulls\n",
    "- **Monitoring and logging** for system health\n",
    "- **Comprehensive testing** and validation\n",
    "\n",
    "### 🎯 What's Next:\n",
    "1. **Run the setup** to enable automation\n",
    "2. **Test your first data pull** to verify everything works\n",
    "3. **Let the system collect data** automatically\n",
    "4. **Explore and analyze** your environmental data\n",
    "5. **Share insights** with the Durham community\n",
    "\n",
    "---\n",
    "\n",
    "**Need help?** \n",
    "- 📖 Check the `DATA_MANAGEMENT_README.md` for detailed documentation\n",
    "- 🔍 Use `python scripts/status_check.py` for system health monitoring\n",
    "- 📋 Review logs in the `logs/` directory for troubleshooting\n",
    "\n",
    "**Happy data collecting!** 🌟📊🔬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
